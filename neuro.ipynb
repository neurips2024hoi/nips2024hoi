{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09533da-33de-4f09-b51e-48b6db9c4c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import scipy\n",
    "from ite.cost.x_factory import co_factory\n",
    "from tqdm import tqdm\n",
    "import dill\n",
    "import ast\n",
    "import seaborn as sns\n",
    "from scipy.spatial.distance import cosine\n",
    "import scipy.spatial as sp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statannotations.Annotator import Annotator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45077493-f0fd-4dbd-b5f8-8a0795ff1b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f939cfa-8401-4fbf-afc6-54e68d01ddac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(data, shuffle_indices):\n",
    "    # Create a copy of the original data to avoid modifying the input in place.\n",
    "    shuffled_data = data.copy()\n",
    "\n",
    "    for indices in shuffle_indices:\n",
    "        # Generate a random permutation for the indices.\n",
    "        permutation = np.random.permutation(shuffled_data.shape[0])\n",
    "\n",
    "        # Apply the permutation to the specified indices.\n",
    "        for idx in indices:\n",
    "            shuffled_data[:, idx] = shuffled_data[permutation, idx]\n",
    "\n",
    "    return shuffled_data\n",
    "\n",
    "def Streitberg_4(X, div_func):\n",
    "    n = X.shape[0]\n",
    "\n",
    "    X_fully_shuffled = shuffle_data(X, [[0], [1], [2]])\n",
    "    p1234 = div_func(X, X_fully_shuffled)\n",
    "    p1p234 = div_func(X[:,[1, 2, 3]], X_fully_shuffled[:,[1, 2, 3]])\n",
    "    p2p134 = div_func(X[:,[0, 2, 3]], X_fully_shuffled[:,[0, 2, 3]])\n",
    "    p3p124 = div_func(X[:,[0, 1, 3]], X_fully_shuffled[:,[0, 1, 3]])\n",
    "    p4p123 = div_func(X[:,[0, 1, 2]], X_fully_shuffled[:,[0, 1, 2]])\n",
    "    p12p34 = div_func(shuffle_data(X, [[0, 1]]), X_fully_shuffled)\n",
    "    p13p24 = div_func(shuffle_data(X, [[0, 2]]), X_fully_shuffled)\n",
    "    p14p23 = div_func(shuffle_data(X, [[0, 3]]), X_fully_shuffled)\n",
    "    p1p2p34 = div_func(X[:,[2, 3]], X_fully_shuffled[:,[2, 3]])\n",
    "    p1p3p24 = div_func(X[:,[1, 3]], X_fully_shuffled[:,[1, 3]])\n",
    "    p1p4p23 = div_func(X[:,[1, 2]], X_fully_shuffled[:,[1, 2]])\n",
    "    p2p3p14 = div_func(X[:,[0, 3]], X_fully_shuffled[:,[0, 3]])\n",
    "    p2p4p13 = div_func(X[:,[0, 2]], X_fully_shuffled[:,[0, 2]])\n",
    "    p3p4p12 = div_func(X[:,[0, 1]], X_fully_shuffled[:,[0, 1]])\n",
    "\n",
    "    streitberg_4 = (p1234 - (p1p234 + p2p134 + p3p124 + p4p123) - (p12p34 + p13p24 + p14p23)\n",
    "                    + 2 * (p1p2p34 + p1p3p24 + p1p4p23 + p2p3p14 + p2p4p13 + p3p4p12))\n",
    "\n",
    "    return streitberg_4\n",
    "\n",
    "def Streitberg_3(X, div_func):\n",
    "    n = X.shape[0]\n",
    "\n",
    "    X_fully_shuffled = shuffle_data(X, [[0], [1]])\n",
    "    p123 = div_func(X, X_fully_shuffled)\n",
    "    p1p23 = div_func(X[:,[1, 2]], X_fully_shuffled[:,[1, 2]])\n",
    "    p2p13 = div_func(X[:,[0, 2]], X_fully_shuffled[:,[0, 2]])\n",
    "    p3p12 = div_func(X[:,[0, 1]], X_fully_shuffled[:,[0, 1]])\n",
    "\n",
    "    streitberg_3 = p123 - (p1p23 + p2p13 + p3p12)\n",
    "\n",
    "    return streitberg_3\n",
    "\n",
    "def Streitberg_2(X, div_func):\n",
    "    n = X.shape[0]\n",
    "\n",
    "    X_fully_shuffled = shuffle_data(X, [[0]])\n",
    "    p12 = div_func(X, X_fully_shuffled)\n",
    "    \n",
    "    return p12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a5f1ce-b5ee-40e2-a5ac-c0a423a9a549",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/movement/rate_data_20ms.pkl', 'rb') as f:\n",
    "    movement = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17f380b-05cb-481f-a242-83e9a3a3a0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials = defaultdict(lambda: defaultdict(int))\n",
    "for day in range(44):\n",
    "    for direction in ['DownLeft', 'Left', 'UpLeft', 'Up', 'UpRight', 'Right', 'DownRight']:\n",
    "        n_trials[day][direction] = np.shape(movement[day][direction])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5e2ffd-24bf-44bd-9c98-8d24d9a6b2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# most trials\n",
    "n_trials[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495afd3f-22b5-4160-8ad4-3296c705ce7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampledata(my_list, samples=500, k=2, seed=331):\n",
    "    unique_sets = set()\n",
    "\n",
    "    local_random = random.Random()\n",
    "    local_random.seed(seed)\n",
    "\n",
    "    total_combinations = scipy.special.comb(len(my_list), k)\n",
    "    max_unique_sets = min(samples, total_combinations)\n",
    "\n",
    "    while len(unique_sets) < max_unique_sets:\n",
    "        random_set = frozenset(local_random.sample(my_list, k=k))\n",
    "        unique_sets.add(random_set)\n",
    "\n",
    "    unique_sets = [list(s) for s in unique_sets]\n",
    "    return unique_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12482ae-64fb-4580-a43d-f6eaf3671597",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_name = 'BDTsallis_KnnK'  # dim >= 1\n",
    "co = co_factory(cost_name, mult=True, alpha=0.5, k=20)  # cost object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ede91d-5248-4ebe-b258-bbc105883299",
   "metadata": {},
   "outputs": [],
   "source": [
    "directions = ['DownLeft', 'Left', 'UpLeft', 'Up', 'UpRight', 'Right', 'DownRight']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d8dd8f-442b-4827-9ff1-4b981f3d24dd",
   "metadata": {},
   "source": [
    "# Compare Prep with Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced1f79b-98c4-4ba0-badb-26cf9c96e7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_hoi(data):\n",
    "    hoi_dict = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))\n",
    "    for direction in tqdm(['DownLeft', 'Left', 'UpLeft', 'Up', 'UpRight', 'Right', 'DownRight']):\n",
    "        for time in range(60):\n",
    "            X = data[direction][:,:,time]\n",
    "            ### 2 way hoi ###\n",
    "            unique_sets = sampledata(range(12), samples=500, k=2, seed=331)\n",
    "            for sample_ind in unique_sets:\n",
    "                info = Streitberg_2(X[:, sample_ind], co.estimation)\n",
    "                hoi_dict[direction][time][tuple(sample_ind)] = info\n",
    "            ### 3 way hoi ###\n",
    "            unique_sets = sampledata(range(12), samples=500, k=3, seed=331)\n",
    "            for sample_ind in unique_sets:\n",
    "                info = Streitberg_3(X[:, sample_ind], co.estimation)\n",
    "                hoi_dict[direction][time][tuple(sample_ind)] = info\n",
    "            ### 4 way hoi ###\n",
    "            unique_sets = sampledata(range(12), samples=500, k=4, seed=331)\n",
    "            for sample_ind in unique_sets:\n",
    "                info = Streitberg_4(X[:, sample_ind], co.estimation)\n",
    "                hoi_dict[direction][time][tuple(sample_ind)] = info\n",
    "    return hoi_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b33e2b0-a647-4c7a-8560-0930d65f8048",
   "metadata": {},
   "outputs": [],
   "source": [
    "hoi_dict = find_hoi(movement[17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202b9271-f19a-4549-a25e-7a94230c6a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_hoi(hoi_dict):# Initialize dictionaries to store the sums for nodes of different lengths\n",
    "    sums_2_nodes = {}\n",
    "    sums_3_nodes = {}\n",
    "    sums_4_nodes = {}\n",
    "\n",
    "    # Iterate over the dictionary to compute the sums\n",
    "    for direction, time_dict in hoi_dict.items():\n",
    "        for time, node_info in time_dict.items():\n",
    "            for nodes, info in node_info.items():\n",
    "                node_length = len(nodes)\n",
    "                abs_info = abs(info)\n",
    "                if node_length == 2:\n",
    "                    sums_2_nodes.setdefault(direction, {}).setdefault(time, 0)\n",
    "                    sums_2_nodes[direction][time] += abs_info\n",
    "                elif node_length == 3:\n",
    "                    sums_3_nodes.setdefault(direction, {}).setdefault(time, 0)\n",
    "                    sums_3_nodes[direction][time] += abs_info\n",
    "                elif node_length == 4:\n",
    "                    sums_4_nodes.setdefault(direction, {}).setdefault(time, 0)\n",
    "                    sums_4_nodes[direction][time] += abs_info\n",
    "    return sums_2_nodes, sums_3_nodes, sums_4_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5520ce-7a93-4c9b-9b82-00cedc699256",
   "metadata": {},
   "outputs": [],
   "source": [
    "sums_2, sums_3, sums_4 = sum_hoi(hoi_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487b40a2-345a-4bd0-8f32-5ba109f078d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_sum(sums_2_nodes, length):\n",
    "    for direction, time_dict in sums_2_nodes.items():\n",
    "        for time, value in time_dict.items():\n",
    "            sums_2_nodes[direction][time] /= length\n",
    "    return sums_2_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a84048f-02a8-4b6e-b59d-9c2cb2648d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "sums_2 = normalise_sum(sums_2, 66)\n",
    "sums_3 = normalise_sum(sums_3, 220)\n",
    "sums_4 = normalise_sum(sums_4, 495)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef62ef83-0761-4813-8042-2a707e65eb14",
   "metadata": {},
   "source": [
    "# classification using all combinations instead of sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc52e487-27ad-418d-a578-8e92ff0275dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(hoi_dict):\n",
    "    # Create an empty DataFrame\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # Iterate over each direction and time\n",
    "    for direction, time_data in hoi_dict.items():\n",
    "        for time, comb_data in time_data.items():\n",
    "            # Create a temporary DataFrame from the combination data\n",
    "            temp_df = pd.DataFrame(list(comb_data.values()), index=list(comb_data.keys()), columns=[f'{direction}_{time}'])\n",
    "            temp_df.index.names = ['Comb']\n",
    "            # Transpose the temporary DataFrame and reset the index\n",
    "            temp_df = temp_df.T.reset_index(drop=True)\n",
    "            # Concatenate this temporary DataFrame with the main DataFrame\n",
    "            df = pd.concat([df, temp_df], axis=0)\n",
    "\n",
    "    label = [0]*25 + [1]*35\n",
    "    label = label*7\n",
    "    df['label'] = label\n",
    "\n",
    "    label2 = [0]*60 + [1]*60 +[2]*60 +[3]*60 +[4]*60 +[5]*60 +[6]*60\n",
    "    df['direction'] = label2\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9171534a-b320-4f4f-a9ed-79fb1eb66a5f",
   "metadata": {},
   "source": [
    "# Find all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e8e5a9-786f-4e8c-be00-66f548149ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hoi_dict_full = {}\n",
    "for day in [1, 2, 3, 5, 11, 17, 19, 24, 26, 27, 28, 31]:\n",
    "     hoi_dict_full[day] = find_hoi(movement[day])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4926e6cc-3614-452d-9211-3a745eb53593",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/movement/hoi_12day.pkl', 'rb') as f:\n",
    "    hoi_dict_full = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c01357-db56-4dac-95b6-28bd787d88d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf_allnodes_label(df, label, n_components):\n",
    "    X = df.iloc[:, :-2]\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    y = df[label]\n",
    "    acc = {}\n",
    "    \n",
    "    X_2 = PCA(n_components=n_components).fit_transform(X[:, :66])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_2, y, test_size=0.15, random_state=986)\n",
    "    clf_2way = LogisticRegression(random_state=10).fit(X_train, y_train)\n",
    "    acc['2'] = accuracy_score(clf_2way.predict(X_test), y_test)\n",
    "    # print('2: train:', clf_2way.score(X_train, y_train), 'test:', accuracy_score(clf_2way.predict(X_test), y_test))\n",
    "    \n",
    "    X_23 = PCA(n_components=n_components).fit_transform(X[:, :286])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_23, y, test_size=0.15, random_state=986)\n",
    "    clf_23way = LogisticRegression(random_state=10).fit(X_train, y_train)\n",
    "    acc['23'] = accuracy_score(clf_23way.predict(X_test), y_test)\n",
    "    # print('23: train:', clf_23way.score(X_train, y_train),'test:', accuracy_score(clf_23way.predict(X_test), y_test))\n",
    "    \n",
    "    X_234 = PCA(n_components=n_components).fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_234, y, test_size=0.15, random_state=986)\n",
    "    clf_234way = LogisticRegression(random_state=10).fit(X_train, y_train)\n",
    "    acc['234'] = accuracy_score(clf_234way.predict(X_test), y_test)\n",
    "    # print('234: train:', clf_234way.score(X_train, y_train),'test:', accuracy_score(clf_234way.predict(X_test), y_test))\n",
    "    \n",
    "    X_3 = PCA(n_components=n_components).fit_transform(X[:, 66:286])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_3, y, test_size=0.20, random_state=986)\n",
    "    clf_3way = LogisticRegression(random_state=10, penalty='l2', solver='liblinear').fit(X_train, y_train)\n",
    "    acc['3'] = accuracy_score(clf_3way.predict(X_test), y_test)\n",
    "    # print('3: train:', clf_3way.score(X_train, y_train),'test:', accuracy_score(clf_3way.predict(X_test), y_test))\n",
    "\n",
    "    X_4 = PCA(n_components=n_components).fit_transform(X[:, 286:])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_4, y, test_size=0.20, random_state=986)\n",
    "    clf_4way = LogisticRegression(random_state=10, penalty='l2', solver='liblinear').fit(X_train, y_train)\n",
    "    acc['4'] = accuracy_score(clf_4way.predict(X_test), y_test)\n",
    "    # print('4: train:', clf_4way.score(X_train, y_train),'test:', accuracy_score(clf_4way.predict(X_test), y_test)) \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd31fd7b-daed-48c4-95b3-a0a5aebee2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_stage_var = {}\n",
    "for day in [1, 2, 3, 5, 11, 17, 19, 24, 26, 27, 28, 31]:\n",
    "    df1 = create_df(hoi_dict_full[day])\n",
    "    # print('day', day)\n",
    "    acc_stage_var[day] = clf_allnodes_label(df1, 'label', 66)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
